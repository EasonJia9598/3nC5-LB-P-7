---
title: "Optimizing Diversity in Decision Models of Evolutionary Reinforcement Learning"
publishedAt: "2024-04-08"
summary: "Research and development of novel reinforcement learning algorithms using KL divergence for diversity maintenance, improving model performance and scalability in AI-driven decision-making."
images:
  - "/images/work/image.png"
  - "/images/work/image2.png"
  - "/images/work/image3.png"
team:
  - name: "Ethan (Zesheng) Jia"
    role: "Affiliate AI Researcher â€“ Dalhousie University"
    avatar: "/images/avatar.jpg"
    linkedIn: "https://www.linkedin.com/in/zeshengjia/"
---

## Overview

This research focuses on improving **diversity maintenance in evolutionary reinforcement learning (RL)** by introducing **KL divergence-based algorithms**. The goal is to optimize decision-making efficiency while maintaining **a diverse range of policies** in agent-based learning models.

## Key Features

- **KL Divergence-Based Diversity Maintenance**  
  Developed and implemented novel **KL divergence-based algorithms** to prevent policy collapse, leading to a **300% improvement** in model diversity and performance.

- **Custom Statistical Methods for Model Efficiency**  
  Designed **dynamic thresholding and hypothesis testing techniques** to enhance training scalability, allowing **agent-based RL models to optimize decision processes more effectively**.

- **Performance Optimization with CUDA**  
  Leveraged **NVIDIA CUDA with C/C++** to accelerate training, achieving a **30% improvement** in execution speeds for large-scale decision-making tasks.

- **Significant Performance Gains**  
  Increased **training speed by 10x** and **maximum performance score by 2x** compared to the original baseline model.

## Technologies Used

- **Python, C, C++**: Core development and implementation of RL algorithms.
- **CUDA**: GPU acceleration for large-scale reinforcement learning experiments.
- **PyTorch & TensorFlow**: Deep learning frameworks for model training.
- **Evolutionary Reinforcement Learning**: Applied state-of-the-art methods for agent-based decision-making.

## Challenges and Learnings

- **Balancing Exploration & Exploitation**  
  Ensuring **RL agents maintain diverse yet optimized strategies** required careful **tuning of diversity thresholds** and **reward function regularization**.

- **Computational Bottlenecks in Large-Scale Models**  
  Optimizing RL models for **scalability** required **CUDA acceleration**, leading to a **30% improvement** in computational efficiency.

- **Algorithmic Complexity vs. Practical Implementation**  
  The implementation of **KL divergence-based diversity control** introduced additional computational costs, which were mitigated through **parallel computing optimizations**.

## Outcome

This research significantly improved **reinforcement learning model efficiency** by **enhancing diversity maintenance and accelerating training**. The findings contribute to the development of **more robust AI-driven decision models** applicable to **finance, robotics, and autonomous systems**.
